{"train/policy_loss": -0.09044407873880118, "train/value_loss": 13.542177419364453, "train/total_loss": 13.451733340625651, "train/episode": 23, "_timestamp": 1745984101.2168005, "benchmark/num_episode_buffer": 78, "benchmark/episode": 23, "_runtime": 1999.4578804969788, "_step": 23, "benchmark/batch_elapsed_time": 1590.0327203273773, "benchmark/avg_episode_time": 79.50163601636886, "benchmark/avg_reward": 35.08982455880916}