{"train/policy_loss": -0.030327802803367377, "train/value_loss": 34.173343980312346, "train/total_loss": 34.14301617750898, "train/episode": 55, "_timestamp": 1745981279.0594194, "_runtime": 501.2208433151245, "_step": 55}